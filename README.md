<h1>League_of_Legends_prediction</h1>

by Bofu Zou and Zhuoxuan Ju

## Framing the Problem

### Problem Identification

Exploring about the prediction on the winning or losing result of a team in one game prior to the result being determined is our focusing point for this project. We would like to form a model that input the relavent data and return the result of that game. We are building a classifier with a binary classification. 

The reason why we choose the topic is because the winning trend in early and mid games are signifcant and can influence the final result of a game. Our model will predict the result of a team in one game by analyzing the team's resources gained(gold, experience(xp), kills(creat a gap of gold earned and xp learned between you and opposite side) and the difference between this team and its opposite team in early game(10 mins) and mid game(15 mins). Our response variable is the result of that game. It will be a binary result which 1 equals to win and 0 equals to lose. The result of each game is the hardest to predict just by watching the game untill the game actually ends (one team destorys the opposing Nexus) and thus we choose it as our response variable.

The metric we take is accuracy. Firstly, the observation doesn't contain class imbalance, since we want to predict one team's result in the game, and it is a binary result. In other words, the winning games and the losing games are equal. The errors (false positive and false negative) are also equally bad (given the two confusion matrix plots below, generated by the baseline model and final model on the testing data). Thus, we choose accuracy over F1-score as to evaluate our model.

The features we would use in our model would be columns generated during the game like `"golddiffat15"` (gold difference at 15 mins). Columns like `"totalcs"` might contain more decisive data, but we can't use it since we are tring to predict the team's result in a game prior to game over while this column is only able to be generated after the game.

In order to explore our prediction problem, we performed the same data cleaning steps as we do in project3: Investigation-on-League-of-Legends. In addition, we drop the rows that are not contains our target values. For example, in the game from the league LPL, the data like `"golddiffat15"` did not being recoreded inside the dataframe, and we drop it in order to not confuse for our model. At last, we drop the irrelevant columns with missing values from the dataframe


## Baseline Model

For our Baseline Model, we used `Pipeline` to encode several features and applied `DecisionTreeClassifier`(set the max_depth to 12). To evaluate our modelâ€™s ability to generalize to unseen data, we used `train_test_split()` seperating traning data and testing data. 

We used `"side"`, `"league"`, `"killsat10"`, `"xpdiffat10"`  as the features in our baseline model.

`"side"` - this is one nominal column. We implement one hot encode that particular column in order to get it to fit in our model.

`"league"` - this is a nominal column, and we one hot encoded this column to 1 and 0 for each league in the game.

`"killsat10"` - this is a quantitative column, and it represents the numbers of kills for the team at 10 minute. There will be no change on this column.

`"xpdiffat10"` - this is a quantitative column. It is the difference in experience between two teams at 10 minute.

We fitted the model to the training data that we splitted previously and tested the model on both the training set and testing set. The average score of our trained model is around 0.79 on training data and around 0.58 on testing data.

We believe the model is not good one. First, the accuracy score of testing data is relatively lower than that of the training data, which indicates that the model has overfitting issue(ability to generalize to unseen data is restricted). Second, we solely included four features, which will limit the model's ability to generate more accurate prediction. Last but not least, the features we selected are not highly correlated with the games' results. For instance, we only include the kills and experience at 10 minute, but the first 10 minute cannot fully represent the game, since the game might last much longer than only 10 minute.

There is the confusion matrix for our testing data result:

<iframe src="output.png" width=800 height=600 frameBorder=0></iframe>

## Final Model


In our Final Model, our features are:

`"side"` - this is one nominal column. We implement one hot encode that particular column in order to get it to fit in our model.

`"killsat15"` - this is one quantitative column that record the kills from the team at 15 minutes from the game start.

`"xpdiffat15"` - this is one quantitative column which represent the experience the team get at the first 15 minutes.

`"opp_killsat15"` - this is a quantitative column, and it is the number of kills from the opposite team at the first 15 minutes.

`"golddiffat15"` - this is a quantitative column, and it is the difference in the gold recevied between two teams at the first 15 minutes.

`"csdiffat15"` - this is a quantitative column that records the difference of the soliders that two teams kill in the first 15 minutes.

`"goldat15"` - this is a quantitative column that the gold the team received in the first 15 minutes.


In order to get a better model, we delete the feature `"league"`, because the different leagues that the games are in is not a variable that will affect our result. For example, the game content will be the same for the match in LPL and LCK. Also, we changed the features `"killsat10"` and `"xpdiffat10"` to `"killsat15"` and `"xpdiffat15"`, because we want to get higher accuracy for the prediction, and we believe the datas that are collected at the first 15 minutes can give our model more information on the game's trend, and thus the model will work better on predict the game result.

We added more features. Firstly `"opp_killsat15"`, as the description above, it records the kills from the opposite team at the first 15 minutes. We believe this column can generate and represent the strength of the oppsite team. With that information, we can somewhat increase the complexity of the model. However it will not cause overfitting for our model because the match is more complicated than just determined by kills.

Secondly `"golddiffat15"` and `"goldat15"`, `"golddiffat15"` represents the difference in the amount of gold received in game for both team in the first 15 minutes. `"goldat15"` shows the gold the team gain. In the game, gold is used for purchasing powerful items to strengthen their power. The higher amount of gold, the stronger the players will be. So with this information, the model can include more variables for predict the result of the game. 

Lastly `"csdiffat15"`, this feature represents the numbers of soldiers that the team kills in the first 15 minutes. If this features is high, it can represent this team have more advantages that their opponent, since they have a higher priority in the lane. This will add more chance to win for this team. Thus, we consider it as one of our feature.


For our model, we chose `DecisionTreeClassifier()` as our prediction model, and we will return in a binary result. Inside our model, we split the data into training and testing model and construct the `ColumnTransformer()`. Specifically, we one hot encoded the `"side"`, and using `Binarizer()` for both `"golddiffat15"` and `"xpdiffat15"`. Applying `StandardScaler()` on the `"goldat15"` can standardize the data. Later on, we form a `FunctionTransformer()` which calculates the difference in kills for the team and their opponent team. After that, we used Cross Validation to find the best paramters for the `ColumnTransformer()`. In the next step, we apply one `GridSearchCV()` in order to find the best paramters for `DecisionTreeClassifier()` in our model. Later on, we contruct a Pipeline to train our data. 

The testing data overall performance of our Final Model is around 0.73. It is a huge inprovement comparing to our Baseline Model. Specifically, we include more features inside our Final Model, and the precision of our model is higher than the Baseline Model, since we contain only the datas that collecte from the first 15 minutes. This highly increase the complexity for our model. In addition, the training data's overall performance is around 0.76. This shows that our model does not occur overfitting condition. 

There is our confusion matrix for the testing data overall performance:

<iframe src="output2.png" width=800 height=600 frameBorder=0></iframe>


### Testing Model

We created one testing model to try out different combinations, and the testing data accuracy of our model is only about 0.65. The features that we included are `"side"`, `"league"`, `"killsat10"`, `"xpdiffat10"`, `"opp_killsat15"`, `"goldat10"`. We believe the reason of such low accuracy is because we include some not comprehensive features inside the model. For example, we included `"killsat10"`, `"xpdiffat10"`, `"goldat10"`. We originally considered that those data are important for the development of the game. Specifically, the gold that each team earned can help them purchase powerful items which can increase their demage to other players. They are all the data that being collected at the first 10 minutes of the game. As we mentioned above, each game can last more than 10 minutes and even 1 hour. Therefore, we think this model is not good enough to predict the result correctly.


## Fairness Analysis

